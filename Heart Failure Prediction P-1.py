# -*- coding: utf-8 -*-
"""CSE316 (AI LAB FINAL PROJECT).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-sp52ElEgw6IHVHPInleqeULADyKpUGG

# ***Heart Failure Prediction Using Python***  

### **About this dataset**
Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worlwide.
Heart failure is a common event caused by CVDs and this dataset contains 12 features that can be used to predict mortality by heart failure.

Most cardiovascular diseases can be prevented by addressing behavioural risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity and harmful use of alcohol using population-wide strategies.

People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management wherein a machine learning model can be of great help.

### **Developed By**

# **TEAM VIBRANIUM**

>>> Sadia Jannat (201-15-3136) 

>>> Arfin Shariar (201-15-3316)

>>> Aflatul Kawser (201-15-3500)

>>> Maynul Haque Jim (201-15-3067)

>>> Istiyak Ifti (201-15-3086)

>>> Sk Radoun Rifat (201-15-3542)

# **CODING**

CODE START FROM HERE
                  --------------------

---
"""

#Import Essiential Python Libraries and Module Here
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sb

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier

# Drive Mounting
from google.colab import drive
drive.mount('/content/drive')

#Read Dataset CSV File
data_set = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Machine Learning/heart_failure_clinical_records_dataset.csv")

#Output of Dataset
data_set

#Checking the Info of Dataset
data_set.info()

#Shape of Our Dataset
data_set.shape

"""### **Output Justify:**
--------------- 

We Have 299 rows and 13 Columns on our Dataset

# **Data PreProcessing Part**
-----
"""

#Checking Dataset contains any null value or not
data_set.isnull().sum()

"""### **Output Justify:**
--------------------------
Our Dataset Contains No Null Value. So We don't need to handle missing value or Null Value for our data set.
"""

#Divide Dataset In 2 Split

x = data_set.iloc[:,0:-1].values # x is our Independent Variable

y = data_set.iloc[:,-1].values # y is our Dependent Variable. Its always dependent on x.

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3, random_state = 0)

"""### **Standard Scaling**
________
"""

#Standard Scaler
st_x = StandardScaler()
x_train = st_x.fit_transform(x_train)
x_test = st_x.fit_transform(x_test)

"""### **Label Encoding**
______________________
Our Dataset contains all values numeric. There is no string value in our Data set. So, Label Encoding not need for our Data Set.

### **One Hot Encoding**
_______________

We also no need of use One_Hot_Encoder

# **Logestic Regression**
-----------
"""

LR = LogisticRegression(random_state = 0)

LR.fit(x_train,y_train)

y_predict_LR = LR.predict(x_test)

y_predict_LR

#Report Analysis for Logistic Regression
print("Report Analysis for Logistic Regression")
print("----------------------------------------")
#Confusion Matrics
print("Confusion Matrix: \n",metrics.confusion_matrix(y_test,y_predict_LR))

#Accuracy Report
print("Accuracy in Point value: ",metrics.accuracy_score(y_test,y_predict_LR))
print("Accuracy in Percentage Value: ",metrics.accuracy_score(y_test,y_predict_LR)*100 )

#Classification Report
print("Classification Report: \n",metrics.classification_report(y_test,y_predict_LR))

#ROC & AOC CURVE VISUALIZATION
y_predict_prob = LR.predict_proba(x_test)[:,1]
LR_AOC = metrics.roc_auc_score(y_test,y_predict_prob)
print("AUC SCORE: ",LR_AOC)

False_PR,True_PR,thresholdvalues = metrics.roc_curve(y_test,y_predict_prob)
plt.plot([0,1],[0,1],color='yellow',linestyle='--')
print("Logistic Regression (area= " +str(LR_AOC)+")")
plt.plot(False_PR,True_PR)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

print("The End Of Logistic Regression")

"""# **Support Vector Classifier (SVC)** **& ROC AND AOC CURVE**




"""

# Apllying Support Vector Machine
sm = SVC(probability = True)
sm.fit(x_train,y_train)

y_predict_sm = sm.predict(x_test)

y_predict_sm

#Report Analysis for Support Vector Machine(SVC):
print("Report Analysis for Support Vector Machine(SVC):")
print("-------------------------------------------------")
#Confusion Matrics
print("Confusion Matrix: \n",metrics.confusion_matrix(y_test,y_predict_sm))

#Accuracy Report
print("Accuracy in Point value: ",metrics.accuracy_score(y_test,y_predict_sm))
print("Accuracy in Percentage Value: ",metrics.accuracy_score(y_test,y_predict_sm)*100 )

#Classification Report
print("Classification Report: \n",metrics.classification_report(y_test,y_predict_sm))

#ROC & AOC CURVE VISUALIZATION
y_predict_sm_prob = sm.predict_proba(x_test)[:,1]
sm_AOC = metrics.roc_auc_score(y_test,y_predict_sm_prob)
print("AUC SCORE: ",sm_AOC)

F_PR,T_PR,thresholdvalues = metrics.roc_curve(y_test,y_predict_sm_prob)
plt.plot([0,1],[0,1],color='Green',linestyle='--')
print("Support Vector Classifier (area= " +str(sm_AOC)+")")
plt.plot(F_PR,T_PR)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

print("End of Support Vector Classifier")

"""# **Random Forest & ROC AOC CURVE**"""

#Applying Random Forest
RF = RandomForestClassifier(n_estimators=10,criterion="entropy")
RF.fit(x_train,y_train)

y_RF_pred = RF.predict(x_test)

print("Report Analysis for Random Forest(with 10 decision tree)")
print("---------------------------------------------------------")
#Confusion Matrix
print("Confusion Matrix: \n",metrics.confusion_matrix(y_test,y_RF_pred))

#Accurcy Check
print("Accuracy in point value: ",metrics.accuracy_score(y_test,y_RF_pred))
print("Accuracy in Percentage value: ",metrics.accuracy_score(y_test,y_RF_pred)*100)

#Classification Report
print("Classification Report for Random Forest: \n",metrics.classification_report(y_test,y_RF_pred))

y_pred_RF_prob = RF.predict_proba(x_test)[:,1]
RF_aoc = metrics.roc_auc_score(y_test,y_pred_RF_prob)
print("AOC Score: ",RF_aoc)

f_p_r,t_p_r,thresholdvalues = metrics.roc_curve(y_test,y_pred_RF_prob)
plt.plot([0,1],[0,1],color = 'BLACK',linestyle = '--')
print("Random Forest Classifier (area= " +str(RF_aoc)+")")
plt.plot(f_p_r,t_p_r)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

print("The End of Random Forest Classfier")

"""# **Decision Tree** & ROC CURVE DRAW

"""

#Aapplying Decision Tree
dt = DecisionTreeClassifier(criterion="entropy",random_state = 0)
dt.fit(x_train,y_train)

y_dt_pred = dt.predict(x_test)

#Report Analysis for Decision Tree
#Confusion Matrix
print("Report Analysis for Decision Tree")
print("----------------------------------")
print("Confusion Matrix:\n",metrics.confusion_matrix(y_test,y_dt_pred))

#Accuracy Report
print("Accuracy Report in Point Value: ",metrics.accuracy_score(y_test,y_dt_pred))
print("Accuracy Report in Percentage Value: ",metrics.accuracy_score(y_test,y_dt_pred)*100)

#Classification Report
print("Classificaition Report for Decision Tree:\n",metrics.classification_report(y_test,y_dt_pred))

#ROC & AOC CURVE VISUALIZATION
y_predict_dt_prob = dt.predict_proba(x_test)[:,1]
dt_AOC = metrics.roc_auc_score(y_test,y_predict_dt_prob)
print("AUC SCORE: ",dt_AOC)

FPR,TPR,thresholdvalues = metrics.roc_curve(y_test,y_predict_dt_prob)
plt.plot([0,1],[0,1],color='grey',linestyle='--')
print("Decision Tree Classifier (area= " +str(dt_AOC)+")")
plt.plot(FPR,TPR)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

"""# **K-Nearist Neighbour & ROC,AOC CURVE**"""

# Applying KNN in Data_Set
kn = KNeighborsClassifier(n_neighbors=5,metric = 'minkowski', p=2)

kn.fit(x_train,y_train)

y_kn_predict = kn.predict(x_test)

## Report Analysis for K-Nearist neighbours(KNN)
#Confusion Matrix
print("Report Analysis for K-Nearist neighbours(KNN)")
print("-----------------------------------------------")
print("Confusion Matrix:\n",metrics.confusion_matrix(y_test,y_kn_predict))

#Accuracy Check
print("Accuracy Report in point value: ",metrics.accuracy_score(y_test,y_kn_predict))
print("Accuracy Report in Percentage: ",metrics.accuracy_score(y_test,y_kn_predict)*100)

#Classification Report
print("Classification Report:\n",metrics.classification_report(y_test,y_kn_predict))

#ROC and AOC CURVE Visualization for KNN
y_predict_knn_prob = kn.predict_proba(x_test)[:,1]
kn_AOC = metrics.roc_auc_score(y_test,y_predict_knn_prob)
print("AUC SCORE: ",kn_AOC)

f_pr,t_pr,thresholdvalues = metrics.roc_curve(y_test,y_predict_knn_prob)
plt.plot([0,1],[0,1],color='red',linestyle='--')
print("K-Nearest Neighbours Classifier (area= " +str(sm_AOC)+")")
plt.plot(f_pr,t_pr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

print("End of K-nearest Neighbours Algorithm")

"""# **ADAboost apply and ROC & AOC CURVE draw**"""

# Applying ADAboost Classifer
ADBC = AdaBoostClassifier(n_estimators=50,learning_rate=1)
ADBC.fit(x_train,y_train)

y_adbc_pred = ADBC.predict(x_test)

# Report Analysis for ADABoost Classifier
print("Report Analysis for ADABoost Classfier")
print("---------------------------------------")
print("Confusion Matrix: \n",metrics.confusion_matrix(y_test,y_adbc_pred))

#Accuracy check
print("Accuracy Report in Point Value: ",metrics.accuracy_score(y_test,y_adbc_pred))
print("Accuracy Report in Percentage Value: ",metrics.accuracy_score(y_test,y_adbc_pred)*100)

#Classification Report
print("Classsification Report: \n",metrics.classification_report(y_test,y_adbc_pred))

